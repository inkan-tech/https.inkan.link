---
title: My Boss is an AI (Part 2)
date: 2023-07-18T09:48:50+02:00
draft: false
language: en
featured_image: images/posts/mail-gpt.jpg
summary: In the second part of our series "My Boss is an AI", we explore how cybercriminals can access CEO's emails and use AI to mimic their writing style. We also discuss why standard security recommendations are no longer sufficient in the face of these new threats. Finally, we present how Sealfie, an innovative cybersecurity solution, can help businesses detect forgery and identity theft.
description: Explore how cybercriminals use AI to mimic the writing style of CEOs and why standard security recommendations are no longer sufficient. Discover how Sealfie can help detect forgery and identity theft. Read "My Boss is an AI (Part 2)" to learn more about these cybersecurity threats and how to combat them.
author: Nicolas Thomas
authorimage: images/global/NicolasHeadShot.webp
categories: blog
tags: [ BEC, GPT, Cybersecurity,LLM,IdentityTheft]
---
# My Boss is an AI (Part 2)

In the first part of this series, ["My Boss is an AI"](https://inkan.link/en/posts/blog-my-boss-is-an-ai/), we explored how artificial intelligence (AI) has facilitated voice cloning and how it has impacted cybersecurity. Today, we delve deeper by examining how cybercriminals can access CEO's emails and use AI to mimic their writing style.

## How can a criminal gain access to a CEO's email?

Access to a CEO's email can be obtained through a phishing attack. The criminal sends an email that appears to come from a legitimate source, prompting the recipient to reveal sensitive information, such as passwords. Once the criminal has access to the email, they can then collect a large amount of textual data.

## Training an LLM (AI like chatGPT) to mimic writing style

This textual data can then be used to train an LLM (large-scale language model). An LLM is a form of AI that has been trained on a large amount of text. It is capable of mimicking a person's writing style based on the textual data it has received. By using an LLM, a criminal can create emails that appear to have been written by the CEO themselves. To learn more about training LLMs, you can consult this [video](https://www.youtube.com/watch?v=aBNcbyakt1w).

## Why standard security recommendations are no longer sufficient

However, even if companies follow the precautionary recommendations of cybersecurity agencies like FBI, it may not be enough. Cybercriminals can now use LLMs to create very credible fakes at a relatively low cost. Standard recommendations, such as verifying the sender's email address and being wary of suspicious attachments, are no longer sufficient in the face of these new threats.

## Using Sealfie for enhanced security

In the face of these challenges, companies can turn to solutions like [Sealfie](https://sealf.ie/en). Sealfie offers a technology that allows for the reliable verification of the true decision-makers and the right contacts, adding minimal friction. It can even replace heavy processes that are often poorly followed, especially during vacation periods or in emergencies. By using Sealfie, companies can certify all kinds of transactions, whether physical or digital, and detect forgery and identity theft.

## Conclusion

Don't wait the criminals now have their own LLM [wormGPT](https://thehackernews.com/2023/07/wormgpt-new-ai-tool-allows.html) which is best known to help in the business email compromise fraud.
Only by adopting proactive and sophisticated solutions like Sealfie can companies stay one step ahead of cybercriminals and protect their valuable digital assets. The innovative approach of [Inkan.link](https://inkan.link/en/posts/blog-my-boss-is-an-ai/), labeled deeptech and radically simple to use, makes the lives of criminals more complex, while simplifying cybersecurity protection for businesses.

